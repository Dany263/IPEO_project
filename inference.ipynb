{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4f910f5",
   "metadata": {},
   "source": [
    "# Inference notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d70bbd6",
   "metadata": {},
   "source": [
    "### 1. Imports & Device selection (CPU / GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7dc322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "from tifffile import imread\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc3de16",
   "metadata": {},
   "source": [
    "### 2. Loading test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a529c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"data/dataset_split.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "test_df = df[df['split'] == 'test']\n",
    "ytest = test_df['EUNIS_cls'].values\n",
    "\n",
    "tabular_cols = test_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "tabular_cols = [c for c in tabular_cols if c != 'EUNIS_cls']\n",
    "\n",
    "Xtest_tensor = torch.tensor(test_df[tabular_cols].values, dtype=torch.float32)\n",
    "image_test_ids = test_df['id'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7518973c",
   "metadata": {},
   "source": [
    "### 3. Loading trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebab9031",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_image_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "class CombinedTabularImageModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Combines tabular data (MLP) and images (CNN) for classification.\n",
    "    Possibility to choose the CNN architecture (from the Image defined).\n",
    "    \"\"\"\n",
    "    def __init__(self, tabular_input_dim, n_classes=17, tabular_hidden=[128, 64], image_model='Resnet50', pretrained=True, dropout=0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        # --- Tabular branch ---\n",
    "        layers = []\n",
    "        input_dim = tabular_input_dim\n",
    "        for h in tabular_hidden:\n",
    "            layers.append(nn.Linear(input_dim, h))\n",
    "            layers.append(nn.BatchNorm1d(h))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            input_dim = h\n",
    "        self.tabular_mlp = nn.Sequential(*layers)\n",
    "        tabular_feat_dim = tabular_hidden[-1]\n",
    "\n",
    "        # --- Image branch --- ONLY KEEP THE BEST MODEL AND DEFINE HERE ALSO\n",
    "        if image_model == 'Resnet50':\n",
    "            # Return feature vector instead of logits\n",
    "            self.image_model = ImageResNet50(n_classes=2048, pretrained=pretrained, freeze_backbone=True)\n",
    "            self.image_feat_dim = 2048\n",
    "        elif image_model == 'Hypercolumn':\n",
    "            self.image_model = ImageHypercolumnResNet(n_classes=2048 + 1024 + 512 + 256, pretrained=pretrained)\n",
    "            self.image_feat_dim = 2048 + 1024 + 512 + 256\n",
    "        elif image_model == 'CNNfeature':\n",
    "            self.image_model = ImageCNNFeatureMLP(n_classes=256, pretrained=pretrained, hidden_dim=256, dropout=dropout)\n",
    "            self.image_feat_dim = 256\n",
    "        else:\n",
    "            raise NotImplementedError(f\"{image_model} not supported\")\n",
    "\n",
    "        # --- Fusion classifier ---\n",
    "        self.classifier = nn.Sequential(nn.Linear(tabular_feat_dim + self.image_feat_dim, 256), nn.ReLU(), nn.Dropout(dropout), nn.Linear(256, n_classes))\n",
    "\n",
    "    def forward(self, tabular_x, image_x):\n",
    "        # Tabular branch\n",
    "        tab_feat = self.tabular_mlp(tabular_x)\n",
    "        \n",
    "        # Image branch\n",
    "        img_feat = self.image_model(image_x)\n",
    "        if img_feat.ndim == 4:  # if backbone returns (B,C,H,W)\n",
    "            img_feat = F.adaptive_avg_pool2d(img_feat, 1).view(img_feat.size(0), -1)\n",
    "\n",
    "        # Concatenate features\n",
    "        combined = torch.cat([tab_feat, img_feat], dim=1)\n",
    "        out = self.classifier(combined)\n",
    "        return out\n",
    "\n",
    "# replace with your trained model filename\n",
    "model_name = \"Combined_Hypercolumn_1\" \n",
    "\n",
    "# Instantiate the exact same architecture as training\n",
    "input_dim = Xtest_tensor.shape[1]\n",
    "selected_image_model = 'Hypercolumn'  # same as training\n",
    "model = CombinedTabularImageModel(tabular_input_dim=input_dim, n_classes=17, image_model=selected_image_model)\n",
    "\n",
    "# Load the checkpoint weights\n",
    "checkpoint = torch.load(f\"models/{model_name}.pt\", map_location=device)\n",
    "print(checkpoint.keys())\n",
    "print(checkpoint.get('hyperparameters'))\n",
    "print(checkpoint.get('model_type'))\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Move to device\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c12f01",
   "metadata": {},
   "source": [
    "### 4. Selecting 5 test samples\n",
    "We select the first 5 samples from the test set for reproducible inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f894d433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_from_folder(folder_path, img_id):\n",
    "    \"\"\"\n",
    "    Load an RGB aerial image from a folder using PIL.\n",
    "    Returns a PIL Image in RGB format.\n",
    "    \"\"\"\n",
    "    img_path = Path(folder_path) / f\"{img_id}.png\"\n",
    "    if not img_path.exists():\n",
    "        raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    return img\n",
    "\n",
    "folder_path = \"data/images_png\" \n",
    "num_samples = 5\n",
    "sample_indices = range(num_samples)\n",
    "true_labels = ytest[:num_samples]\n",
    "\n",
    "tabular_samples = Xtest_tensor[sample_indices].to(device)\n",
    "\n",
    "image_samples = []\n",
    "image_ids_subset = image_test_ids[:num_samples]\n",
    "\n",
    "for img_id in image_ids_subset:\n",
    "    img = load_image_from_folder(folder_path, img_id)\n",
    "    img_tensor = eval_image_transform(img)\n",
    "    image_samples.append(img_tensor)\n",
    "\n",
    "image_samples = torch.stack(image_samples).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a297ceb",
   "metadata": {},
   "source": [
    "### 5. Running inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111a107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(tabular_samples, image_samples)\n",
    "    pred_labels = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "    print(f\"Predicted labels for {num_samples} samples: {pred_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47e6f7f",
   "metadata": {},
   "source": [
    "### 6. Visualizing predictions vs true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a2efeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, num_samples, figsize=(15, 5))\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    img = load_image_from_folder(folder_path, image_ids_subset[i])\n",
    "    ax.imshow(img)\n",
    "    color = \"green\" if pred_labels[i] == true_labels[i] else \"red\"\n",
    "    ax.set_title(f\"Pred: {pred_labels[i]}\\nTrue: {true_labels[i]}\", color=color)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
