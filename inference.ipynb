{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4f910f5",
   "metadata": {},
   "source": [
    "# Inference notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d70bbd6",
   "metadata": {},
   "source": [
    "### 1. Device selection (CPU / GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7dc322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "from tifffile import imread\n",
    "from io import BytesIO\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc3de16",
   "metadata": {},
   "source": [
    "### 2. Loading test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a529c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"data/dataset_split.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "test_df = df[df['split'] == 'test']\n",
    "ytest = test_df['EUNIS_cls'].values\n",
    "\n",
    "tabular_cols = test_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "tabular_cols = [c for c in tabular_cols if c != 'EUNIS_cls']\n",
    "\n",
    "Xtest_tensor = torch.tensor(test_df[tabular_cols].values, dtype=torch.float32)\n",
    "image_test_ids = test_df['id'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7518973c",
   "metadata": {},
   "source": [
    "### 3. Loading trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebab9031",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_image_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "class CombinedTabularImageModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Combines tabular data (MLP) and images (CNN) for classification.\n",
    "    Possibility to choose the CNN architecture (from the Image defined).\n",
    "    \"\"\"\n",
    "    def __init__(self, tabular_input_dim, n_classes=17, tabular_hidden=[128, 64], image_model='Resnet50', pretrained=True, dropout=0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        # --- Tabular branch ---\n",
    "        layers = []\n",
    "        input_dim = tabular_input_dim\n",
    "        for h in tabular_hidden:\n",
    "            layers.append(nn.Linear(input_dim, h))\n",
    "            layers.append(nn.BatchNorm1d(h))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            input_dim = h\n",
    "        self.tabular_mlp = nn.Sequential(*layers)\n",
    "        tabular_feat_dim = tabular_hidden[-1]\n",
    "\n",
    "        # --- Image branch --- ONLY KEEP THE BEST MODEL AND DEFINE HERE ALSO\n",
    "        if image_model == 'Resnet50':\n",
    "            # Return feature vector instead of logits\n",
    "            self.image_model = ImageResNet50(n_classes=2048, pretrained=pretrained, freeze_backbone=True)\n",
    "            self.image_feat_dim = 2048\n",
    "        elif image_model == 'Hypercolumn':\n",
    "            self.image_model = ImageHypercolumnResNet(n_classes=2048 + 1024 + 512 + 256, pretrained=pretrained)\n",
    "            self.image_feat_dim = 2048 + 1024 + 512 + 256\n",
    "        elif image_model == 'CNNfeature':\n",
    "            self.image_model = ImageCNNFeatureMLP(n_classes=256, pretrained=pretrained, hidden_dim=256, dropout=dropout)\n",
    "            self.image_feat_dim = 256\n",
    "        else:\n",
    "            raise NotImplementedError(f\"{image_model} not supported\")\n",
    "\n",
    "        # --- Fusion classifier ---\n",
    "        self.classifier = nn.Sequential(nn.Linear(tabular_feat_dim + self.image_feat_dim, 256), nn.ReLU(), nn.Dropout(dropout), nn.Linear(256, n_classes))\n",
    "\n",
    "    def forward(self, tabular_x, image_x):\n",
    "        # Tabular branch\n",
    "        tab_feat = self.tabular_mlp(tabular_x)\n",
    "        \n",
    "        # Image branch\n",
    "        img_feat = self.image_model(image_x)\n",
    "        if img_feat.ndim == 4:  # if backbone returns (B,C,H,W)\n",
    "            img_feat = F.adaptive_avg_pool2d(img_feat, 1).view(img_feat.size(0), -1)\n",
    "\n",
    "        # Concatenate features\n",
    "        combined = torch.cat([tab_feat, img_feat], dim=1)\n",
    "        out = self.classifier(combined)\n",
    "        return out\n",
    "\n",
    "# Instantiate model\n",
    "input_dim = Xtest_tensor.shape[1]\n",
    "\n",
    "# replace with your trained model filename\n",
    "model_name = \"Combined_Hypercolumn_1\" \n",
    "selected_image_model = 'Hypercolumn'\n",
    "\n",
    "model = CombinedTabularImageModel(tabular_input_dim=input_dim, n_classes=17, image_model=selected_image_model)\n",
    "model.load_state_dict(torch.load(f\"models/{model_name}.pt\", map_location=device))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c12f01",
   "metadata": {},
   "source": [
    "### 4. Selecting 5 test samples\n",
    "We select the first 5 samples from the test set for reproducible inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f894d433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_from_zip(zip_path, img_id):\n",
    "    \"\"\"\n",
    "    Load an RGB aerial image from a zip archive using tifffile (robust for GeoTIFF).\n",
    "    Returns a PIL Image in RGB format.\n",
    "    \"\"\"\n",
    "    with zipfile.ZipFile(zip_path, 'r') as archive:\n",
    "        with archive.open(f\"{img_id}.tif\") as file:\n",
    "            img_array = imread(BytesIO(file.read()))\n",
    "\n",
    "    # Ensure uint8 format for visualization / PIL\n",
    "    if img_array.dtype != np.uint8:\n",
    "        img_array = img_array.astype(np.uint8)\n",
    "\n",
    "    # Some TIFFs may be (H, W, C) already\n",
    "    # Ensure RGB\n",
    "    if img_array.ndim == 3 and img_array.shape[2] >= 3:\n",
    "        img_array = img_array[:, :, :3]\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected image shape for {img_id}: {img_array.shape}\")\n",
    "\n",
    "    return Image.fromarray(img_array, mode=\"RGB\")\n",
    "\n",
    "num_samples = 5\n",
    "sample_indices = range(num_samples)\n",
    "true_labels = ytest[:num_samples]\n",
    "\n",
    "tabular_samples = Xtest_tensor[sample_indices].to(device)\n",
    "\n",
    "image_samples = []\n",
    "zip_path = \"data/images.zip\"\n",
    "image_ids_subset = image_test_ids[:num_samples]\n",
    "\n",
    "for img_id in image_ids_subset:\n",
    "    img = load_image_from_zip(zip_path, img_id)\n",
    "    img_tensor = eval_image_transform(img)\n",
    "    image_samples.append(img_tensor)\n",
    "\n",
    "image_samples = torch.stack(image_samples).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a297ceb",
   "metadata": {},
   "source": [
    "### 5. Running inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111a107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(tabular_samples, image_samples)\n",
    "    pred_labels = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "    print(f\"Predicted labels for {num_samples} samples: {pred_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47e6f7f",
   "metadata": {},
   "source": [
    "### 6. Visualizing predictions vs true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a2efeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, num_samples, figsize=(15, 5))\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    for i, ax in enumerate(axes):\n",
    "        img_array = tiff.imread(zip_ref.open(f\"{img_id}.tif\"))\n",
    "\n",
    "        # Ensure 3-channel RGB\n",
    "        if img_array.ndim == 2:\n",
    "            img_array = np.stack([img_array]*3, axis=-1)\n",
    "        elif img_array.shape[0] in [1, 3]:  # channel-first\n",
    "            img_array = np.transpose(img_array, (1, 2, 0))\n",
    "\n",
    "        img = Image.fromarray(img_array.astype(np.uint8))\n",
    "        \n",
    "        ax.imshow(img)\n",
    "        color = \"green\" if pred_labels[i] == true_labels[i] else \"red\"\n",
    "        ax.set_title(f\"Pred: {pred_labels[i]}\\nTrue: {true_labels[i]}\", color=color)\n",
    "        ax.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
